{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/header.png\"></center>\n",
    "\n",
    "<h1><center>Алгоритмы интеллектуальной обработки больших объемов данных</center></h1>\n",
    "<hr>\n",
    "<h2><center>Меры качества кластеризации, уменьшение размерности признаков</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "try:\n",
    "    from ipywidgets import interact, IntSlider, fixed, FloatSlider\n",
    "except ImportError:\n",
    "    print u'Так надо'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cluster Validity and Quality Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Оценка качества кластеризации при известном groud truth\n",
    "\n",
    "Пусть $\\hat{\\pi}$ - это полученное разбиение на кластеры, а $\\pi^*$ - ground truth. \n",
    "\n",
    "<center><img src='http://cse3521.artifice.cc/images/iris-true-class-sepal.png' width=800></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Adjusted Rand Index\n",
    "\n",
    "$$ \\text{Rand}(\\hat{\\pi},\\pi^*) = \\frac{a + d}{a + b + c + d} \\text{,}$$\n",
    "где \n",
    "* $a$ количество пар объектов, находящихся в одинаковых кластерах в $\\hat{\\pi}$ и\n",
    "$\\pi^*$, \n",
    "* $b$ ($c$) количество пар объектов в одном и том же кластере в  $\\hat{\\pi}$ ($\\pi^*$), но в разных в  $\\pi^*$ ($\\hat{\\pi}$)\n",
    "* $d$ количество пар объектов в разных кластерах в $\\hat{\\pi}$ и $\\pi^*$\n",
    "\n",
    "Adjusted Rand Index - корректировка Rand index:\n",
    "\n",
    "$$\\text{ARI}(\\hat{\\pi},\\pi^*)   = \\frac{\\text{Rand}(\\hat{\\pi},\\pi^*) - \\text{Expected}}{\\text{Max} - \\text{Expected}}$$\n",
    "\n",
    "Так же есть **[Normalized Mutual Information](http://en.wikipedia.org/wiki/Mutual_information)**, но результаты этой метрики схожи с ARI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Индекс Жаккара\n",
    "$$ Jac(\\hat{\\pi}, \\pi^*) = \\frac{a}{a + b + c}$$\n",
    "\n",
    "#### Точность, полнота и F-мера\n",
    "$$ Precision(\\hat{\\pi}, \\pi^*) = \\frac{a}{a + b} $$\n",
    "$$ Recall(\\hat{\\pi}, \\pi^*) = \\frac{a}{a + c} $$\n",
    "$$ F-measure(\\hat{\\pi}, \\pi^*) = \\frac{2Precision \\cdot Recall}{Precision + Recall} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Критерий Silhouette\n",
    "\n",
    "Пусть дана кластеризация в $K$ кластеров, и объект $i$ попал в $C_k$\n",
    "\n",
    "* $a(i)$ - среднее расстояние от $i$ объекта до объектов из $C_k$\n",
    "* $b(i) = min_{j \\neq k} b_j(i)$,  где $b_j(i)$ - среднее расстояние от $i$ объекта до объектов из $C_j$\n",
    "$$\n",
    "silhouette(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}\n",
    "$$\n",
    "Средний silhouette для всех точек из $\\mathbf{X}$ является критерием качества кластеризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/sil1.png' width=1200></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/sil2.png' width=1200></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dunn Index\n",
    "\n",
    "Введем обозначения:\n",
    "* $\\delta(C_k,C_l) = \\min\\limits_{x_i\\in C_k, x_j \\in C_l}d(x_i, x_j) $ - расстояние между кластерами $C_k, C_l$\n",
    "* $\\Delta(C_k) = \\max\\limits_{x_i, x_j \\in C_k}d(x_i, x_j)$ - диаметр кластера\n",
    "\n",
    "Тогда \n",
    "$$DI = \\frac{\\min\\limits_{k \\neq l} \\delta(C_k, C_l)}{\\max\\limits_{(C_k)} \\Delta(C_k)} $$\n",
    "\n",
    "*Существует несколько вариаций данного индекса*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Davies–Bouldin Index\n",
    "\n",
    "Введем обозначения\n",
    "* $S(C_k) = 1/|C_k|\\sum\\limits_{x_i \\in C_k} d(x_i, \\mu_{c_k})$ - разброс данных внутри кластера $C_k$\n",
    "\n",
    "$$ DB = \\frac{1}{K}\\sum\\limits_{C_k}\\max\\limits_{C_l \\neq C_k}\\frac{S(C_K) + S(C_l)}{d(\\mu_{c_k}, \\mu_{c_l})} $$\n",
    "\n",
    "*Существует несколько вариаций данного индекса*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### FYI\n",
    "* [Обзор мер качества 1](http://www.sciencedirect.com/science/article/pii/S003132031200338X)\n",
    "* [Обзор мер качества 2](https://cran.r-project.org/web/packages/clusterCrit/vignettes/clusterCrit.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Методы уменьшения размерности признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/curse.png' width=800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Проклятье размерности\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\">$d=2$<img src='https://jeremykun.files.wordpress.com/2016/01/2d-distances.png' width=400></th>\n",
    "    <th class=\"tg-031e\">$d=2 \\dots 100$<img src='https://jeremykun.files.wordpress.com/2016/01/distances-animation.gif' width=400></th>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "$$ \\lim_{d \\rightarrow \\infty} \\frac{\\text{dist}_{max} - \\text{dist}_{min}}{\\text{dist}_{min}} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Проклятье размености\n",
    "\n",
    "<center><img src='http://www.visiondummy.com/wp-content/uploads/2014/04/curseofdimensionality.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Способы понижения размерности\n",
    "\n",
    "Избавляться от размерности можно методами **отбора признаков (Feature Selection)** и методами **уменьшения размерности (Feature Reduction)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Feature Selection (для Supervised Models)\n",
    "Методы деляться на следующие группы:\n",
    "* Filter methods \n",
    "    * Признаки рассматриваются независимо друг от друга\n",
    "    * Изучается индивидуальный \"вклад\" призника в предсказываемую переменную\n",
    "    * Быстрое вычисление\n",
    "    * *Пример?*\n",
    "* Wrapper methods\n",
    "    * Идет отбор группы признаков\n",
    "    * Может быть оооочень медленным, но качество, обычно, лучше чем у Filter Methods\n",
    "    * Примеры: Stepwise feature selection for regression, [Boruta Algorithm](https://www.google.ru/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&ved=0ahUKEwif5biy-fTWAhXkYJoKHbdxCLAQFgg2MAE&url=https%3A%2F%2Fwww.jstatsoft.org%2Farticle%2Fview%2Fv036i11%2Fv36i11.pdf&usg=AOvVaw3tyiHN0BCe2fkkAA6xEVDE)\n",
    "* Embedded methods\n",
    "    * Отбор признаков \"зашит\" в модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Filter method - Mutual Information\n",
    "$$MI(y,x) = \\sum_{x,y} p(x,y) \\ln\\left[\\frac{p(x,y)}{p(x)p(y)}\\right]$$\n",
    "Сколько информации $x$ сообщает об $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic = pd.read_csv('titanic.csv')\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15087048925218183"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "pd.crosstab(df_titanic.Survived, df_titanic.Sex, normalize=True)\n",
    "\n",
    "mutual_info_score(df_titanic.Survived, df_titanic.Sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Wrapper Methods - Recursive Feature Elimination\n",
    "\n",
    "При данном подходе из линейной модели последовательно удаляются признаки с наименьшим коэффициентом\n",
    "\n",
    "Выбор итоговой модели можно производить по одному из следующих критериев, оценивающих сложность и точность модели:\n",
    "* [AIC](https://ru.wikipedia.org/wiki/%D0%98%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D1%8B%D0%B9_%D0%BA%D1%80%D0%B8%D1%82%D0%B5%D1%80%D0%B8%D0%B9_%D0%90%D0%BA%D0%B0%D0%B8%D0%BA%D0%B5)\n",
    "* [BIC](https://en.wikipedia.org/wiki/Bayesian_information_criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Principal Component Analysis\n",
    "## Метод Главных Компонент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# PCA\n",
    "\n",
    "* Позволяет уменьшить число переменных, выбрав самые изменчивые из них\n",
    "* Новые переменные являются линейной комбинацией старых переменных\n",
    "* Переход к ортономированному базису\n",
    "\n",
    "<center><img src='http://www.visiondummy.com/wp-content/uploads/2014/05/correlated_2d.png' width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Построение PCA\n",
    "*  Пусть $x \\in \\mathbb{R}^d$ - вектор признаков для какого-то объекта. Будем считать, что $x$ - центрировано и отшкалировано. $E[x_i] = 0, V[x_i] = 1, \\quad i=1 \\dots d$\n",
    "* Требуется найти линейное преобразование, которое задается ортогональной матрицей $A$:\n",
    "$$ pc = A^\\top x $$\n",
    "\n",
    "* $pc_i = a_i^\\top x = x^\\top a_i$\n",
    "* $cov[x] = E[(x - E[x])(x - E[x])^\\top] = Exx^\\top = \\Sigma$ -  ковариационная матрица"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Построение PCA\n",
    "\n",
    "* $E[pc_i] = E[a_i^\\top x] = a_i^\\top E[x]$\n",
    "* $cov[pc_i, pc_j] = E[pc_i \\cdot pc_j^\\top] = a_i^\\top \\Sigma a_j $\n",
    "* $\\Sigma$ - симметричная и положительно определенная матрица.\n",
    "    * Собственные числа $\\lambda_i \\in \\mathbb{R}, \\lambda_i \\geq 0$ (Будем считать, что $\\lambda_1 \\geq \\lambda_2  \\geq \\dots \\geq \\lambda_d $)\n",
    "    * Собственные вектора при $\\lambda_i \\neq \\lambda_j $ ортогональны: $v_i^\\top v_j = 0$\n",
    "    * У каждого $\\lambda_i$ есть единственный $v_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Первая компонента\n",
    "$$ pc_1 = a_1 ^\\top x $$\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "V[pc_1] = a_1^\\top \\Sigma a_1 \\rightarrow \\max_a \\\\\n",
    "a_1^\\top a_1 = 1\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "* Строим функцию лагранжа\n",
    "$$ \\mathcal{L}(a_1, \\nu) = a_1^\\top \\Sigma a_1 - \\nu (a_1^\\top a_1 - 1) \\rightarrow max_{a_1, \\nu}$$\n",
    "* Считаем производую по $a_1$\n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial a_1} = 2\\Sigma a_1 - 2\\nu a_1 = 0 $$\n",
    "* Получается, что $a_1$ один из собственных векторов матрицы $\\Sigma$, причем при $\\lambda_1$\n",
    "$$ V[pc_1] = a_1^\\top \\Sigma a_1 = \\lambda_i a_1^\\top a_1 = \\lambda_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Вторая компонента\n",
    "$$ pc_2 = a_2 ^\\top x $$\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "V[pc_2] = a_2^\\top \\Sigma a_2 \\rightarrow \\max_a \\\\\n",
    "a_2^\\top a_2 = 1 \\\\\n",
    "cov[pc_1, pc_2] = a_2^\\top \\Sigma a_1 = \\lambda_1 a_2^\\top a_1 = 0\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "* Строим функцию лагранжа\n",
    "$$ \\mathcal{L}(a_2, \\nu, \\tau) = a_2^\\top \\Sigma a_2 - \\nu (a_2^\\top a_2 - 1) - \\tau a_2^\\top a_1 \\rightarrow max_{a_1, \\nu}$$\n",
    "\n",
    "Аналогичными выкладками приходим к тому, что $a_2$ - собственный вектор $\\Sigma$ при $\\lambda_2$\n",
    "\n",
    "и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Singular Value Decomposition\n",
    "\n",
    "Для любой матрицы $X$ размера $n \\times m$ и ранга $r$ можно найти разложение вида:\n",
    "$$ X = U S V^\\top ,$$\n",
    "где \n",
    "* $U$ - унитарная матрица, состоящая из собственных векторов $XX^\\top$\n",
    "* $V$ - унитарная матрица, состоящая из собственных векторов $X^\\top X$\n",
    "* $S$ - диагональная матрица с сингулярными числами $s_i = \\sqrt{\\lambda_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SVD\n",
    "Матрицы $U$ и $V$ ортогональны и могут быть использованы для перехода к ортогональному базису:\n",
    "$$ XV = US $$\n",
    "\n",
    "Сокращение размерности заключается в том, что вместо того, чтобы умножать $X$ не на всю матрицу $V$, а лишь на первые $k<m$ её столбцов - матрицу $V'$\n",
    "\n",
    "Квадраты сингулярных чисел в $S$ содержат дисперсию, объясненную в главных компонентах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/pca_svd.png' width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MNIST, DIGITS\n",
    "<center><img src='images/digits.png' width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MNIST PCA\n",
    "\n",
    "<center><img src='http://nikhilbuduma.com/img/autoencoder_digit_exp.png' width=1200></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Резюме\n",
    "\n",
    "* PCA понижает размерность признакового пространства\n",
    "* Новые компоненты являются линейной комбинацией исходных признаков\n",
    "* Новые компоненты - ортогональны\n",
    "* Можно применять в моделях и для визуализации\n",
    "* [PCA SVD туториал](https://www.cs.princeton.edu/picasso/mats/PCA-Tutorial-Intuition_jp.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# t-SNE\n",
    "## t-distributed stochastic neighbor embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Идея\n",
    "\n",
    "* Перейти в пространство меньшей размерности так, чтобы расстояния между объектами в новом пространстве были подобны расстояниям в исходном пространстве.\n",
    "* Это многомерное шкалирование!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/mds.png' width =1200></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* t-SNE - почти про это, но вместо этого мы будем пытаться перенести окрестность точек из исходного пространства в пространоство меньшей размерности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Схожесть между объектами в исходном пространстве $\\mathbb{R}^m$\n",
    "$$\n",
    "p(i, j) = \\frac{p(i | j) + p(j | i)}{2n}, \\quad p(j | i) = \\frac{\\exp(-\\|\\mathbf{x}_j-\\mathbf{x}_i\\|^2/{2 \\sigma_i^2})}{\\sum_{k \\neq i}\\exp(-\\|\\mathbf{x}_k-\\mathbf{x}_i\\|^2/{2 \\sigma_i^2})}\n",
    "$$\n",
    "$\\sigma_i$ неявно задается пользователем\n",
    "* Схожесть между объектами в целевом пространстве $\\mathbb{R}^k, k << m$\n",
    "$$\n",
    "q(i, j) = \\frac{g(|\\mathbf{y}_i - \\mathbf{y}_j|)}{\\sum_{k \\neq l} g(|\\mathbf{y}_i - \\mathbf{y}_j|)}\n",
    "$$ \n",
    "где $g(z) = \\frac{1}{1 + z^2}$ - распределение Коши (t-распределение Стьюдента с 1 степенью свободы)\n",
    "* Критерий\n",
    "$$\n",
    "J_{t-SNE}(y) = KL(P \\| Q) = \\sum_i \\sum_j p(i, j) \\log \\frac{p(i, j)}{q(i, j)} \\rightarrow \\min\\limits_{\\mathbf{y}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Дивергенция Кульбака-Лейблера\n",
    "\n",
    "* Насколько распределение $P$ отличается от распределения $Q$?\n",
    "$$\n",
    "KL(P \\| Q) = \\sum_z P(z) \\log \\frac{P(z)}{Q(z)}\n",
    "$$\n",
    "\n",
    "<center><img src='http://www.science-emergence.com/media/images/381.png' width=1200></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Оптимизация\n",
    "\n",
    "* Оптимизируем $J_{t-SNE}(y)$ с помощью градиентного спуска\n",
    "\n",
    "$$\\frac{\\partial J_{t-SNE}}{\\partial y_i}=4 \\sum_j(p(i,j)−q(i,j))(y_i−y_j)g(|y_i−y_j|)$$\n",
    "\n",
    "* [Статья](http://jmlr.csail.mit.edu/papers/volume9/vandermaaten08a/vandermaaten08a.pdf)\n",
    "* [Примеры](http://lvdmaaten.github.io/tsne/)\n",
    "* [Демо и советы](http://distill.pub/2016/misread-tsne/)\n",
    "    * t-SNE может быть нестабильным\n",
    "    * Размеры полученных сгустков могут ничего не значить\n",
    "    * Расстояния между кластерами могут ничего не значить\n",
    "    * Полностью шумовые данные могут выдать структуру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='http://lvdmaaten.github.io/tsne/examples/mnist_tsne.jpg' width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/mainfold.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Вопросы?\n",
    "\n",
    "## Пожалуйста, оставьте отзыв о лекции"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "livereveal": {
   "theme": "serif",
   "transition": "concave",
   "width": "1024px"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "513px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "none",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "toc_position": {
   "height": "973px",
   "left": "0px",
   "right": "1708px",
   "top": "109px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
