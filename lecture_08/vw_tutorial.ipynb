{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/header.png\">\n",
    "\n",
    "<h1><center>Алгоритмы интеллектуальной обработки больших объемов данных</center></h1>\n",
    "<hr>\n",
    "<h2><center>Линейные модели (практика 2 - Vowpal Wabbit)</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://cdn.dribbble.com/users/261617/screenshots/3146111/vw-dribbble_1x.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Vowpal Wabbit](https://github.com/JohnLangford/vowpal_wabbit/wiki) - это библиотека с большим набором оптимизированных итеративных алгоритмов машинного обучения\n",
    "\n",
    "В этом туториале мы применим эту библиотеку с целью решить задачу классификации с помощью логистической регрессии.\n",
    "\n",
    "**Туториалы:**\n",
    "https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial\n",
    "\n",
    "**Туториал для сборки в unix:**\n",
    "https://github.com/JohnLangford/vowpal_wabbit/wiki/v7.0_tutorial.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/dalpozz/creditcardfraud/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = 'creditcard.csv.zip'\n",
    "fn_out_train = 'creditcard_vw_format_train'\n",
    "fn_out_test = 'creditcard_vw_format_test'\n",
    "fn_out_validation = 'creditcard_vw_format_validation'\n",
    "\n",
    "fn_out_train_weight = 'creditcard_vw_format_train_weight'\n",
    "fn_out_test_weight = 'creditcard_vw_format_test_weight'\n",
    "fn_out_validation_weight = 'creditcard_vw_format_validation_weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(fn, compression='zip', header=0, sep=',', quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Class'] = df['Class']* 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time** - the seconds elapsed between each transaction and the first transaction in the dataset. Numeric  \n",
    "**V1** - First principle component Numeric  \n",
    "**V2** - Second principle component Numeric  \n",
    "**V3** - Third principle component Numeric  \n",
    "...  \n",
    "**V28** - Twenty-eighth principle component Numeric  \n",
    "**Amount** - Transaction Amount Numeric   \n",
    "**Class** - The actual classification classes Numeric  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "Given the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification.\n",
    "\n",
    "The dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available on http://mlg.ulb.ac.be/BruFence and http://mlg.ulb.ac.be/ARTML\n",
    "\n",
    "Please cite: Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формат данных\n",
    "\n",
    "[Описание формата](https://github.com/JohnLangford/vowpal_wabbit/wiki/Input-format)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Label] [Importance] [Base] [Tag]|Namespace Features |Namespace Features ... |Namespace Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 1.0 zebra|MetricFeatures:3.28 height:1.5 length:2.0 |Says black with white stripes |OtherFeatures NumberOfLegs:4.0 HasStripes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем данные к этому формату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skip_columns = {'Class', 'Index', 'Time'}\n",
    "\n",
    "def df_to_file(file_name, data):\n",
    "    with open(file_name, 'w') as f:\n",
    "        for row in tqdm_notebook(data.itertuples()):\n",
    "            features = row._asdict()\n",
    "            features_formatted = ' '.join('{}:{}'.format(k, v) for k, v in features.iteritems() if k not in skip_columns)\n",
    "            f.write('{} | {}\\n'.format(row.Class, features_formatted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train, validation = train_test_split(train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_file(fn_out_train, train)\n",
    "df_to_file(fn_out_validation, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh -s \"$fn_out_train\" \"$fn_out_validation\" \"$fn_out_test\"\n",
    "\n",
    "wc -l $1\n",
    "head $1\n",
    "wc -l $2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Команды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Описание аргументов](https://github.com/JohnLangford/vowpal_wabbit/wiki/Command-line-arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В vw реализован модифицированный градиентный спуск: http://www.cs.cmu.edu/~sross1/publications/uai13_normalized.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sh -s \"$fn_out_train\" \"$fn_out_validation\" \"$fn_out_test\"\n",
    "\n",
    "vw -d $1 -f ./simple_model.vw \\\n",
    "--sgd --adaptive --normalized --invariant \\\n",
    "--loss_function=logistic -l 0.5  --decay_learning_rate 0.95 \\\n",
    "--passes 4 --holdout_off --cache_file ./data.cache\n",
    "\n",
    "rm ./data.cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sh -s \"$fn_out_train\" \"$fn_out_validation\" \"$fn_out_test\"\n",
    "\n",
    "vw -i ./simple_model.vw -t -d $2 -p ./simple_model_predictions.vw --link=logistic \\\n",
    "--invert_hash ./simple_model.vw.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./simple_model.vw.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head simple_model_predictions.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('simple_model_predictions.vw') as pred_file:\n",
    "    validation_prediction = [float(label) for label in pred_file.readlines()]\n",
    "\n",
    "auc = roc_auc_score(validation['Class'], validation_prediction)\n",
    "curve = roc_curve(validation['Class'], validation_prediction)\n",
    "\n",
    "plt.plot(curve[0], curve[1]);\n",
    "plt.plot([0,1], [0,1])\n",
    "plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('test AUC = %f' % (auc)); plt.axis([-0.05,1.05,-0.05,1.05]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Взвешивание объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим вес меньшему классу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C помощью фунции `compute_class_weight` посчитайте веса классов и напишите функцию `df_to_file_weight`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_file_weight(fn_out_train_weight, train)\n",
    "df_to_file_weight(fn_out_validation_weight, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh -s \"$fn_out_train_weight\" \"$fn_out_validation_weight\" \"$fn_out_test_weight\"\n",
    "\n",
    "vw -d $1 -f ./model_weights.vw \\\n",
    "--sgd --adaptive --normalized --invariant \\\n",
    "--loss_function=logistic -l 0.9 --decay_learning_rate 0.95 \\\n",
    "--passes 4 --holdout_off --cache_file ./data.cache\n",
    "\n",
    "rm ./data.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh -s \"$fn_out_train_weight\" \"$fn_out_validation_weight\" \"$fn_out_test_weight\"\n",
    "\n",
    "vw -i model_weights.vw  -t -d $2 -p model_weights_predictions.vw --link=logistic \\\n",
    "--invert_hash ./model_weights.vw.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!cat model_weights.vw.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_weights_predictions.vw') as pred_file:\n",
    "    validation_prediction = [float(label) for label in pred_file.readlines()]\n",
    "\n",
    "auc = roc_auc_score(validation['Class'], validation_prediction)\n",
    "curve = roc_curve(validation['Class'], validation_prediction)\n",
    "\n",
    "plt.plot(curve[0], curve[1]);\n",
    "plt.plot([0,1], [0,1])\n",
    "plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('test AUC = %f' % (auc)); plt.axis([-0.05,1.05,-0.05,1.05]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследуйте другие \"фичи\", например Stagewise Polynomial, Quadratic features, --nn, --boosting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "179px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
